This paper makes an extraordinary claim: that a few interesting but by
themselves inconsequential ideas from decision theory and physics
together give rise to a
\href{https://concepts.effectivealtruism.org/concepts/the-importance-of-crucial-considerations/}{crucial
consideration} with strong implications for how to
\href{https://en.wikipedia.org/wiki/Effective_altruism}{do the
most good}. In this first section, I will outline the main idea and
forward-reference sections with the full arguments and detailed
elaborations. Afterward, I give an overview of the entire paper, section
by section (section
\ref{an-overview-of-the-paper}).

Consider the following thought experiment, adapted from 
\citeauthor{Hofstadter1983-az}'s \citeyear{Hofstadter1983-az} \textit{Dilemmas
for Superrational Thinkers, Leading Up to a Luring Lottery}:

\begin{quote}
\textbf{Donation game with superrationality.} Hofstadter sends 20
participants the same letter, asking them to respond with a single
letter `C' (for cooperate) or `D' (for defect) without communicating
with the other participants. Hofstadter explains that by sending in `C',
a participant can increase everyone else's payoff by \$2. By sending in
`D', participants can increase their own payoff by \$5. The letter ends
by informing the participants that they were chosen for the similarity
and rationality of their decision mechanisms, particularly in weird
scenarios like this one. It should be noted that every participant only
cares about the balance of her own bank account, and not about
Hofstadter's or that of the other 19 participants. Upon receiving the
letter, should you cooperate or defect?
\end{quote}

Assuming the participants' thought processes are sufficiently similar to
each other, I think we should cooperate because this makes it more
likely that our 19 fellow participants also cooperate (see chapter
\ref{superrationality} and
the references given therein). After all, Hofstadter stated fairly
explicitly that the thought processes of the participants are strongly
correlated. Thus, if we cooperate, we should expect significantly more
of the other participants to cooperate as well than if we defect, which
means that cooperating has higher expected utility. Alternatively, we
may reason that by our choice we determine what the rational choice is
for all participants. Hofstadter calls this idea of cooperation via
correlated decision making \emph{superrationality}.

By itself, superrationality does not seem particularly action-guiding.
Usually, we have other evidence about other agents' behavior and thought
processes such that the evidence we gain from our own decisions is less
important (see section
\ref{superrational-cooperation-on-earth}). To apply superrationality in practice, we
combine it with another intellectually stimulating but by itself
inconsequential hypothesis: we probably live in a vast universe or even
\href{https://en.wikipedia.org/wiki/Multiverse}{multiverse}, most
of which we cannot observe or interact with (see appendix section
\ref{many-agents}). In this paper,
we will use the term ``multiverse'' in a broad sense to refer to any
theory postulating multiple universes, including but not limited to
\href{https://en.wikipedia.org/wiki/Many-worlds_interpretation}{Everett's
many-worlds interpretation} of quantum mechanics. In fact, for
brevity's sake, we will use the term to refer to any theory of physics
that implies the existence of a sufficiently large universe with many
agents, including a merely spatially infinite
universe.\footnote{This is consistent with the terminology by 
  \citet{Tegmark2003-sl} but otherwise
  uncommon.} Some parts of this multiverse are probably inhabited by
intelligent beings like us, some of which surely think about scenarios
like this one in the same way as we do. This is all we need to allow for
the application of superrationality.

The key insight of this paper is that agents in a multiverse are in a
situation structurally similar to the aforementioned donation game if
they care about each other's decisions in far away parts of the
multiverse. Consider the following list of parallels:

\begin{itemize}
\item
  The decisions between some groups of agents are correlated, just like
  those in the donation game.
\item
  Some agents have different goals than others -- a claim for which we
  argue in section
  \ref{orthogonality-of-instrumental-rationality-and-values} -- just like the agents in
  the donation game maximize the balances of different bank accounts.
\item
  On occasion, agents can ``cooperate'' by benefitting the value systems
  of agents in other parts of the multiverse at low costs to themselves.
\item
  As in the donation game, our actions cannot causally influence the
  behavior of other agents in the multiverse.
\end{itemize}

As an example, imagine you have some specific value system like the
reduction of involuntary suffering. You come into a situation in which
involuntary suffering has already been reduced to a very low amount. You
face a choice between two actions:

\begin{itemize}
\item
  You can continue to reduce suffering and increase your own utility and
  that of other suffering reducers by 1.\footnote{Quantifying utility in
    a way that allows for comparison among different agents is
    difficult. For now, we will assume that it is possible. The question
    is revisited in section
    \ref{compromise-strategy}.}
\item
  You can increase the utility of superrational agents in other parts of
  the multiverse who (also) care about things other than suffering
  reduction by 100, e.\,g. by generating a society of agents who live
  happily, produce interesting art, conduct science, explore
  technologies, trade, behave benevolently towards each other, etc.
\end{itemize}

By construction of the thought experiment you care about suffering
reduction only, so you would usually take the first action. But consider
that many agents throughout the multiverse will face very similar
decision problems. For example, there might be an agent who primarily
cares about agents experiencing art and the interestingness of things
and who is facing similarly diminishing returns -- in her world, most
things that could be of interest already exist. Other value systems, on
the other hand, have been ignored in the process of making her world
more interesting. Her world contains many sentient beings with very low
levels of well-being, such as humans experiencing various crises (wars,
loneliness, life-threatening dangers) -- a common theme in art --,
\href{https://foundational-research.org/the-importance-of-wild-animal-suffering/}{wild
animals}, or
\href{https://en.wikipedia.org/wiki/Blood_sport}{blood sports}.
She knows that agents in other parts of the multiverse dislike this
suffering and that she could alleviate them at low
\href{https://en.wikipedia.org/wiki/Opportunity_cost}{opportunity
costs} to herself. Her decision problem is thus structurally similar to
our own. If her thought process is similar to our own, superrationality
applies. If we are nice and follow the heuristic ``fulfill the goals of
other agents in the multiverse whenever the returns are much higher than
the opportunity costs for your own values'', then this makes it more
likely that she will be nice as well, the benefits of which are much
greater than those forgone by our own friendliness.

In general, if after thinking about superrationality we are nice to
other value systems and relinquish opportunities to exploit them, this
makes it more likely that other superrational agents with different
value systems out there, or at least those who think in ways similar to
our own, do the same. And if everyone is friendly in this way, we can
expect to harvest
\href{https://foundational-research.org/gains-from-trade-through-compromise/}{gains
from compromise}
\href{https://foundational-research.org/gains-from-trade-through-compromise/}{--}
everyone will be better off. I will refer to this idea as
\emph{multiverse-wide superrationality}, or MSR for short.

\hypertarget{an-overview-of-the-paper}{\subsection{An overview of the
paper}\label{an-overview-of-the-paper}}

Having read the above introduction, the reader is familiar with the
basic idea of MSR. However, it opens up many further questions, some of
which I attempt to answer in the present paper. Specifically the rest of
this paper makes the following contributions:

\begin{itemize}
\item
  We investigate the mechanism of superrationality (chapter
  \ref{superrationality}).

  \begin{itemize}
  \item
    After elaborating on the argument for superrationality, we survey
    the decision theory literature pertaining to superrational
    cooperation (sections
    \ref{lack-of-knowledge-is-evidential-power-part-i-the-other-agents}
    through \ref{reasons-and-correlations}). Among other things, we argue in favor of
    incorporating ``updatelessness'' into one's decision mechanism.
  \item
    Exactly how much should we cooperate? Considering superrationality,
    how should we decide between actions in this universe to maximize
    our multiverse-wide utility? I will argue that it is best to
    effectively adopt a new utility function in this universe: a
    weighted sum of all superrationalists' utility functions that, if
    adopted by all superrationalists, gives every superrationalist the
    same gains from compromise. This function should be the same for all
    agents with your decision algorithm. (See sections
    \ref{are-the-correlations-strong-enough} through
    \ref{compromise-strategy}.)
  \item
    We show how superrational cooperation fundamentally differs from
    standard causal cooperation (sections
    \ref{no-reciprocity-needed-whom-to-treat-beneficially} and
    \ref{cheating-signaling-and-half-heartedness}). We will see how it requires no
    reciprocity -- we should benefit superrationalists who cannot
    benefit us, because we may correlate with agents who can benefit us
    but whom we cannot benefit.
  \end{itemize}
\item
  Cooperating superrationally with agents elsewhere in the multiverse
  means taking their values into account. Chapter
  \ref{values} explores what these
  values might be and which aspects of these values are relevant for
  MSR.

  \begin{itemize}
  \item
    I argue that (with regard to the decision to cooperate or not) we
    correlate with agents who hold values that differ from ours (section
    \ref{orthogonality-of-instrumental-rationality-and-values}). If this were not the
    case, cooperating with them would be unnecessary except when it
    comes to coordination (see section
    \ref{notes-on-superrational-coordination}).
  \item
    I provide a comprehensive list of prerequisites that must be
    fulfilled for MSR to work (see section
    \ref{necessary-preconditions}).
    For example, we cannot benefit agents who do not care about our part
    of the multiverse (section
    \ref{caring-about-the-multiverse}).
  \item
    Which aspects of other agents' preferences should be taken into
    account? E.g., should it only be ``moral preferences''? To which
    extent should we idealize their preferences, e.\,g. by trying to
    factor out cognitive biases? We motivate and answer these questions
    in section \ref{what-values}.
  \item
    We review different approaches to hypothesizing about the values of
    other agents in the multiverse (section
    \ref{the-values-of-our-superrational-collaborators-in-the-multiverse}),
    the most important ones being evolutionary psychology and the study
    of cultural evolution.
  \end{itemize}
\item
  How does multiverse-wide superrational cooperation shift our
  priorities? What does it recommend in practice? These questions are
  discussed in chapter
  \ref{interventions}. We first
  show how to make policy decisions in the absence of reliable knowledge
  about the values of agents elsewhere in the multiverse (section
  \ref{cooperation-in-the-face-of-uncertainty-about-values}). I then
  recommend a few interventions, such as promoting causal cooperation
  (section \ref{promoting-multiverse-wide-superrationality}) and, perhaps most importantly,
  ensuring that future superintelligent AIs reason correctly about
  decision theory (section
  \ref{making-an-ai-come-up-with-superrational-cooperation-on-its-own}).
\item
  The appendix contains various additional considerations that are
  either less crucial for our decisions or otherwise more tangential,
  yet nonetheless relevant and of interest to at least some readers. For
  example, I give an overview of the small amount of work that is
  closely related to MSR (section
  \ref{related-work}) and explain
  why I find it plausible that we live in a universe or multiverse
  containing many agents with whom we are correlated (section
  \ref{many-agents}). I also argue
  that superrationality has few implications for the interactions
  between agents on Earth (section
  \ref{superrational-cooperation-on-earth}), and hence why this paper specifically
  concerns the application of superrationality in a multiverse-wide (as
  opposed to general) setting.
\end{itemize}

Much more research is needed to answer some of the questions I set out
to explore. This is why I focus more on outlining \emph{how} these
questions can be researched in the future, rather than on trying to
ascertain that all my answers are correct with high confidence.

